{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('Dados/Dados_modelo_3_classes.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    95624\n",
       "0.0    43114\n",
       "2.0    40104\n",
       "Name: classificador, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.classificador.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase</th>\n",
       "      <th>classificador</th>\n",
       "      <th>vetor</th>\n",
       "      <th>media</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>não conheci hugh hefner mas o incomodei por um...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.21389145, -0.029730596, 0.7549353, -0.499...</td>\n",
       "      <td>[[-0.17675245, 0.0870293, 0.26394472, -0.20722...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>ter ou não ter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.09315302, 0.03185695, -0.12452485, 0.4039...</td>\n",
       "      <td>[[-0.12504226, 0.080363445, 0.27332583, 0.0303...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>tem muita delação mentirosa diz haddad ao ser ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.29986688, 0.13091782, 0.29787084, 0.892691...</td>\n",
       "      <td>[[-0.13400397, -0.016666962, 0.2561797, -0.167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>luz da oca não faz justiça ao trabalho do filó...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.21728729, 0.306392, 0.14346391, -0.157233...</td>\n",
       "      <td>[[-0.21889256, 0.0480896, 0.3075508, -0.190740...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-29</th>\n",
       "      <td>mortes goleiro e motorista de ambulância no su...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.7904543, 0.93336624, 0.04384019, -0.326198...</td>\n",
       "      <td>[[-0.05481696, 0.3254648, 0.15226528, -0.16893...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        frase  classificador  \\\n",
       "Data                                                                           \n",
       "2017-09-29  não conheci hugh hefner mas o incomodei por um...            1.0   \n",
       "2017-09-29                                     ter ou não ter            1.0   \n",
       "2017-09-29  tem muita delação mentirosa diz haddad ao ser ...            1.0   \n",
       "2017-09-29  luz da oca não faz justiça ao trabalho do filó...            1.0   \n",
       "2017-09-29  mortes goleiro e motorista de ambulância no su...            1.0   \n",
       "\n",
       "                                                        vetor  \\\n",
       "Data                                                            \n",
       "2017-09-29  [[-0.21389145, -0.029730596, 0.7549353, -0.499...   \n",
       "2017-09-29  [[-0.09315302, 0.03185695, -0.12452485, 0.4039...   \n",
       "2017-09-29  [[0.29986688, 0.13091782, 0.29787084, 0.892691...   \n",
       "2017-09-29  [[-0.21728729, 0.306392, 0.14346391, -0.157233...   \n",
       "2017-09-29  [[0.7904543, 0.93336624, 0.04384019, -0.326198...   \n",
       "\n",
       "                                                        media  \n",
       "Data                                                           \n",
       "2017-09-29  [[-0.17675245, 0.0870293, 0.26394472, -0.20722...  \n",
       "2017-09-29  [[-0.12504226, 0.080363445, 0.27332583, 0.0303...  \n",
       "2017-09-29  [[-0.13400397, -0.016666962, 0.2561797, -0.167...  \n",
       "2017-09-29  [[-0.21889256, 0.0480896, 0.3075508, -0.190740...  \n",
       "2017-09-29  [[-0.05481696, 0.3254648, 0.15226528, -0.16893...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ok_0 = df[df.classificador == 0]\n",
    "#df_minority_4 = df[df.classificador == 4]\n",
    "#df_target_2 = df[df.classificador == 2]\n",
    "#df_majority_1 = df[df.classificador == 1]\n",
    "#df_majority_3 = df[df.classificador == 3]\n",
    "\n",
    "#df_minority_0_downsampled = resample(df_maj_0, replace=False, n_samples=45000)\n",
    "#df_minority_4_upsampled = resample(df_minority_4, replace=True, n_samples=37000)\n",
    "#df_minority_1_downsampled = resample(df_majority_1, replace=False, n_samples=37000)\n",
    "#df_minority_3_downsampled = resample(df_majority_3, replace=False, n_samples=37000)\n",
    "\n",
    "#df_corrected = pd.concat([df_minority_0_downsampled, df_target_2,\n",
    "#                        df_minority_1])\n",
    "#df_corrected.classificador.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    43114\n",
       "2.0    40104\n",
       "Name: classificador, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ok_0 = df[df.classificador == 0] \n",
    "df_maj_1 = df[df.classificador == 1]\n",
    "df_ok_2 = df[df.classificador == 2]\n",
    "\n",
    "df_ds_1 = resample(df_maj_1, replace = False, n_samples = 45000)\n",
    "\n",
    "df_corrected = pd.concat([df_ok_0, df_ok_2])\n",
    "df_corrected.classificador.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = df_corrected.media.apply(np.squeeze, axis=0)\n",
    "X = quantile_transform(pd.DataFrame(X.values.tolist(), index=X.index).to_numpy())\n",
    "y = pd.DataFrame(df_corrected.classificador).apply(np.squeeze, axis=0).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_are_nans = np.isnan(X)\n",
    "X[where_are_nans] = 0\n",
    "np.count_nonzero(where_are_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_split = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ohe = OneHotEncoder()\n",
    "plt.hist(y, bins = [0, 1, 2])\n",
    "y = ohe.fit_transform(np.reshape(y, (-1, 1))).toarray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = val_split) \n",
    "class_names = ['Ruim','Bom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 74896\n",
      "number of test examples = 8322\n",
      "X Training data shape = (74896, 100)\n",
      "Y Training data shape = (74896, 2)\n",
      "X Testing data shape = (8322, 100)\n",
      "Y Testing data shape = (8322, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_val.shape[0]))\n",
    "print ('X Training data shape = ' + str (X_train.shape))\n",
    "print ('Y Training data shape = ' + str (y_train.shape))\n",
    "print ('X Testing data shape = ' + str (X_val.shape))\n",
    "print ('Y Testing data shape = ' + str (y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(16, input_dim=100, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 16)                1616      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 1,922\n",
      "Trainable params: 1,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2341/2341 - 1s - loss: 0.7059 - accuracy: 0.5072 - val_loss: 0.6938 - val_accuracy: 0.5089\n",
      "Epoch 2/1000\n",
      "2341/2341 - 1s - loss: 0.6929 - accuracy: 0.5134 - val_loss: 0.6932 - val_accuracy: 0.5118\n",
      "Epoch 3/1000\n",
      "2341/2341 - 1s - loss: 0.6924 - accuracy: 0.5171 - val_loss: 0.6930 - val_accuracy: 0.5130\n",
      "Epoch 4/1000\n",
      "2341/2341 - 1s - loss: 0.6923 - accuracy: 0.5167 - val_loss: 0.6930 - val_accuracy: 0.5168\n",
      "Epoch 5/1000\n",
      "2341/2341 - 1s - loss: 0.6922 - accuracy: 0.5183 - val_loss: 0.6929 - val_accuracy: 0.5181\n",
      "Epoch 6/1000\n",
      "2341/2341 - 1s - loss: 0.6920 - accuracy: 0.5205 - val_loss: 0.6930 - val_accuracy: 0.5095\n",
      "Epoch 7/1000\n",
      "2341/2341 - 1s - loss: 0.6920 - accuracy: 0.5203 - val_loss: 0.6929 - val_accuracy: 0.5179\n",
      "Epoch 8/1000\n",
      "2341/2341 - 1s - loss: 0.6918 - accuracy: 0.5224 - val_loss: 0.6931 - val_accuracy: 0.5174\n",
      "Epoch 9/1000\n",
      "2341/2341 - 1s - loss: 0.6917 - accuracy: 0.5219 - val_loss: 0.6931 - val_accuracy: 0.5150\n",
      "Epoch 10/1000\n",
      "2341/2341 - 1s - loss: 0.6916 - accuracy: 0.5224 - val_loss: 0.6932 - val_accuracy: 0.5174\n",
      "Epoch 11/1000\n",
      "2341/2341 - 1s - loss: 0.6915 - accuracy: 0.5225 - val_loss: 0.6931 - val_accuracy: 0.5184\n",
      "Epoch 12/1000\n",
      "2341/2341 - 1s - loss: 0.6914 - accuracy: 0.5238 - val_loss: 0.6931 - val_accuracy: 0.5137\n",
      "Epoch 13/1000\n",
      "2341/2341 - 1s - loss: 0.6912 - accuracy: 0.5253 - val_loss: 0.6932 - val_accuracy: 0.5137\n",
      "Epoch 14/1000\n",
      "2341/2341 - 1s - loss: 0.6911 - accuracy: 0.5267 - val_loss: 0.6934 - val_accuracy: 0.5145\n",
      "Epoch 15/1000\n",
      "2341/2341 - 1s - loss: 0.6910 - accuracy: 0.5277 - val_loss: 0.6932 - val_accuracy: 0.5135\n",
      "Epoch 16/1000\n",
      "2341/2341 - 1s - loss: 0.6909 - accuracy: 0.5268 - val_loss: 0.6933 - val_accuracy: 0.5147\n",
      "Epoch 17/1000\n",
      "2341/2341 - 1s - loss: 0.6908 - accuracy: 0.5269 - val_loss: 0.6933 - val_accuracy: 0.5129\n",
      "Epoch 18/1000\n",
      "2341/2341 - 2s - loss: 0.6907 - accuracy: 0.5283 - val_loss: 0.6933 - val_accuracy: 0.5153\n",
      "Epoch 19/1000\n",
      "2341/2341 - 2s - loss: 0.6905 - accuracy: 0.5295 - val_loss: 0.6934 - val_accuracy: 0.5081\n",
      "Epoch 20/1000\n",
      "2341/2341 - 2s - loss: 0.6904 - accuracy: 0.5297 - val_loss: 0.6939 - val_accuracy: 0.5141\n",
      "Epoch 21/1000\n",
      "2341/2341 - 1s - loss: 0.6903 - accuracy: 0.5307 - val_loss: 0.6935 - val_accuracy: 0.5171\n",
      "Epoch 22/1000\n",
      "2341/2341 - 1s - loss: 0.6902 - accuracy: 0.5306 - val_loss: 0.6936 - val_accuracy: 0.5165\n",
      "Epoch 23/1000\n",
      "2341/2341 - 1s - loss: 0.6901 - accuracy: 0.5308 - val_loss: 0.6937 - val_accuracy: 0.5145\n",
      "Epoch 24/1000\n",
      "2341/2341 - 1s - loss: 0.6900 - accuracy: 0.5309 - val_loss: 0.6937 - val_accuracy: 0.5131\n",
      "Epoch 25/1000\n",
      "2341/2341 - 1s - loss: 0.6898 - accuracy: 0.5324 - val_loss: 0.6937 - val_accuracy: 0.5137\n",
      "Epoch 26/1000\n",
      "2341/2341 - 1s - loss: 0.6896 - accuracy: 0.5331 - val_loss: 0.6941 - val_accuracy: 0.5159\n",
      "Epoch 27/1000\n",
      "2341/2341 - 1s - loss: 0.6896 - accuracy: 0.5327 - val_loss: 0.6944 - val_accuracy: 0.5165\n",
      "Epoch 28/1000\n",
      "2341/2341 - 1s - loss: 0.6894 - accuracy: 0.5332 - val_loss: 0.6940 - val_accuracy: 0.5130\n",
      "Epoch 29/1000\n",
      "2341/2341 - 1s - loss: 0.6893 - accuracy: 0.5354 - val_loss: 0.6939 - val_accuracy: 0.5157\n",
      "Epoch 30/1000\n",
      "2341/2341 - 1s - loss: 0.6892 - accuracy: 0.5346 - val_loss: 0.6940 - val_accuracy: 0.5120\n",
      "Epoch 31/1000\n",
      "2341/2341 - 1s - loss: 0.6890 - accuracy: 0.5358 - val_loss: 0.6942 - val_accuracy: 0.5165\n",
      "Epoch 32/1000\n",
      "2341/2341 - 1s - loss: 0.6889 - accuracy: 0.5366 - val_loss: 0.6946 - val_accuracy: 0.5148\n",
      "Epoch 33/1000\n",
      "2341/2341 - 1s - loss: 0.6888 - accuracy: 0.5348 - val_loss: 0.6944 - val_accuracy: 0.5148\n",
      "Epoch 34/1000\n",
      "2341/2341 - 1s - loss: 0.6886 - accuracy: 0.5371 - val_loss: 0.6948 - val_accuracy: 0.5118\n",
      "Epoch 35/1000\n",
      "2341/2341 - 1s - loss: 0.6885 - accuracy: 0.5369 - val_loss: 0.6943 - val_accuracy: 0.5165\n",
      "Epoch 36/1000\n",
      "2341/2341 - 1s - loss: 0.6884 - accuracy: 0.5380 - val_loss: 0.6941 - val_accuracy: 0.5155\n",
      "Epoch 37/1000\n",
      "2341/2341 - 1s - loss: 0.6883 - accuracy: 0.5379 - val_loss: 0.6949 - val_accuracy: 0.5114\n",
      "Epoch 38/1000\n",
      "2341/2341 - 1s - loss: 0.6882 - accuracy: 0.5386 - val_loss: 0.6947 - val_accuracy: 0.5114\n",
      "Epoch 39/1000\n",
      "2341/2341 - 1s - loss: 0.6880 - accuracy: 0.5381 - val_loss: 0.6946 - val_accuracy: 0.5155\n",
      "Epoch 40/1000\n",
      "2341/2341 - 1s - loss: 0.6879 - accuracy: 0.5396 - val_loss: 0.6948 - val_accuracy: 0.5120\n",
      "Epoch 41/1000\n",
      "2341/2341 - 1s - loss: 0.6878 - accuracy: 0.5397 - val_loss: 0.6954 - val_accuracy: 0.5141\n",
      "Epoch 42/1000\n",
      "2341/2341 - 1s - loss: 0.6876 - accuracy: 0.5383 - val_loss: 0.6954 - val_accuracy: 0.5156\n",
      "Epoch 43/1000\n",
      "2341/2341 - 1s - loss: 0.6875 - accuracy: 0.5408 - val_loss: 0.6953 - val_accuracy: 0.5119\n",
      "Epoch 44/1000\n",
      "2341/2341 - 1s - loss: 0.6874 - accuracy: 0.5409 - val_loss: 0.6957 - val_accuracy: 0.5129\n",
      "Epoch 45/1000\n",
      "2341/2341 - 2s - loss: 0.6873 - accuracy: 0.5410 - val_loss: 0.6948 - val_accuracy: 0.5143\n",
      "Epoch 46/1000\n",
      "2341/2341 - 2s - loss: 0.6872 - accuracy: 0.5418 - val_loss: 0.6954 - val_accuracy: 0.5175\n",
      "Epoch 47/1000\n",
      "2341/2341 - 1s - loss: 0.6871 - accuracy: 0.5423 - val_loss: 0.6956 - val_accuracy: 0.5124\n",
      "Epoch 48/1000\n",
      "2341/2341 - 1s - loss: 0.6870 - accuracy: 0.5433 - val_loss: 0.6954 - val_accuracy: 0.5147\n",
      "Epoch 49/1000\n",
      "2341/2341 - 2s - loss: 0.6868 - accuracy: 0.5419 - val_loss: 0.6959 - val_accuracy: 0.5132\n",
      "Epoch 50/1000\n",
      "2341/2341 - 1s - loss: 0.6868 - accuracy: 0.5417 - val_loss: 0.6958 - val_accuracy: 0.5141\n",
      "Epoch 51/1000\n",
      "2341/2341 - 2s - loss: 0.6866 - accuracy: 0.5435 - val_loss: 0.6959 - val_accuracy: 0.5102\n",
      "Epoch 52/1000\n",
      "2341/2341 - 1s - loss: 0.6865 - accuracy: 0.5430 - val_loss: 0.6960 - val_accuracy: 0.5102\n",
      "Epoch 53/1000\n",
      "2341/2341 - 1s - loss: 0.6864 - accuracy: 0.5437 - val_loss: 0.6960 - val_accuracy: 0.5100\n",
      "Epoch 54/1000\n",
      "2341/2341 - 1s - loss: 0.6863 - accuracy: 0.5444 - val_loss: 0.6963 - val_accuracy: 0.5094\n",
      "Epoch 55/1000\n",
      "2341/2341 - 1s - loss: 0.6862 - accuracy: 0.5451 - val_loss: 0.6967 - val_accuracy: 0.5124\n",
      "Epoch 56/1000\n",
      "2341/2341 - 1s - loss: 0.6861 - accuracy: 0.5451 - val_loss: 0.6959 - val_accuracy: 0.5143\n",
      "Epoch 57/1000\n",
      "2341/2341 - 1s - loss: 0.6860 - accuracy: 0.5462 - val_loss: 0.6975 - val_accuracy: 0.5121\n",
      "Epoch 58/1000\n",
      "2341/2341 - 1s - loss: 0.6859 - accuracy: 0.5454 - val_loss: 0.6964 - val_accuracy: 0.5102\n",
      "Epoch 59/1000\n",
      "2341/2341 - 1s - loss: 0.6859 - accuracy: 0.5456 - val_loss: 0.6970 - val_accuracy: 0.5125\n",
      "Epoch 60/1000\n",
      "2341/2341 - 1s - loss: 0.6857 - accuracy: 0.5470 - val_loss: 0.6971 - val_accuracy: 0.5172\n",
      "Epoch 61/1000\n",
      "2341/2341 - 1s - loss: 0.6857 - accuracy: 0.5460 - val_loss: 0.6973 - val_accuracy: 0.5089\n",
      "Epoch 62/1000\n",
      "2341/2341 - 1s - loss: 0.6855 - accuracy: 0.5470 - val_loss: 0.6977 - val_accuracy: 0.5130\n",
      "Epoch 63/1000\n",
      "2341/2341 - 1s - loss: 0.6855 - accuracy: 0.5472 - val_loss: 0.6974 - val_accuracy: 0.5108\n",
      "Epoch 64/1000\n",
      "2341/2341 - 1s - loss: 0.6854 - accuracy: 0.5468 - val_loss: 0.6969 - val_accuracy: 0.5103\n",
      "Epoch 65/1000\n",
      "2341/2341 - 1s - loss: 0.6853 - accuracy: 0.5471 - val_loss: 0.6973 - val_accuracy: 0.5102\n",
      "Epoch 66/1000\n",
      "2341/2341 - 1s - loss: 0.6853 - accuracy: 0.5472 - val_loss: 0.6974 - val_accuracy: 0.5127\n",
      "Epoch 67/1000\n",
      "2341/2341 - 1s - loss: 0.6851 - accuracy: 0.5476 - val_loss: 0.6973 - val_accuracy: 0.5106\n",
      "Epoch 68/1000\n",
      "2341/2341 - 1s - loss: 0.6851 - accuracy: 0.5488 - val_loss: 0.6978 - val_accuracy: 0.5106\n",
      "Epoch 69/1000\n",
      "2341/2341 - 1s - loss: 0.6850 - accuracy: 0.5482 - val_loss: 0.6973 - val_accuracy: 0.5099\n",
      "Epoch 70/1000\n",
      "2341/2341 - 1s - loss: 0.6849 - accuracy: 0.5484 - val_loss: 0.6974 - val_accuracy: 0.5159\n",
      "Epoch 71/1000\n",
      "2341/2341 - 1s - loss: 0.6848 - accuracy: 0.5497 - val_loss: 0.6982 - val_accuracy: 0.5095\n",
      "Epoch 72/1000\n",
      "2341/2341 - 1s - loss: 0.6848 - accuracy: 0.5479 - val_loss: 0.6981 - val_accuracy: 0.5135\n",
      "Epoch 73/1000\n",
      "2341/2341 - 1s - loss: 0.6846 - accuracy: 0.5505 - val_loss: 0.6973 - val_accuracy: 0.5121\n",
      "Epoch 74/1000\n",
      "2341/2341 - 1s - loss: 0.6846 - accuracy: 0.5498 - val_loss: 0.6978 - val_accuracy: 0.5168\n",
      "Epoch 75/1000\n",
      "2341/2341 - 1s - loss: 0.6845 - accuracy: 0.5494 - val_loss: 0.6983 - val_accuracy: 0.5155\n",
      "Epoch 76/1000\n",
      "2341/2341 - 2s - loss: 0.6845 - accuracy: 0.5496 - val_loss: 0.6980 - val_accuracy: 0.5133\n",
      "Epoch 77/1000\n",
      "2341/2341 - 2s - loss: 0.6844 - accuracy: 0.5504 - val_loss: 0.6974 - val_accuracy: 0.5148\n",
      "Epoch 78/1000\n",
      "2341/2341 - 1s - loss: 0.6843 - accuracy: 0.5508 - val_loss: 0.6981 - val_accuracy: 0.5123\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2341/2341 - 1s - loss: 0.6842 - accuracy: 0.5511 - val_loss: 0.6997 - val_accuracy: 0.5123\n",
      "Epoch 80/1000\n",
      "2341/2341 - 1s - loss: 0.6841 - accuracy: 0.5509 - val_loss: 0.6980 - val_accuracy: 0.5126\n",
      "Epoch 81/1000\n",
      "2341/2341 - 1s - loss: 0.6841 - accuracy: 0.5514 - val_loss: 0.6987 - val_accuracy: 0.5108\n",
      "Epoch 82/1000\n",
      "2341/2341 - 1s - loss: 0.6840 - accuracy: 0.5526 - val_loss: 0.6983 - val_accuracy: 0.5135\n",
      "Epoch 83/1000\n",
      "2341/2341 - 1s - loss: 0.6839 - accuracy: 0.5515 - val_loss: 0.6986 - val_accuracy: 0.5114\n",
      "Epoch 84/1000\n",
      "2341/2341 - 1s - loss: 0.6839 - accuracy: 0.5499 - val_loss: 0.6980 - val_accuracy: 0.5125\n",
      "Epoch 85/1000\n",
      "2341/2341 - 1s - loss: 0.6838 - accuracy: 0.5517 - val_loss: 0.6987 - val_accuracy: 0.5114\n",
      "Epoch 86/1000\n",
      "2341/2341 - 2s - loss: 0.6836 - accuracy: 0.5512 - val_loss: 0.6991 - val_accuracy: 0.5071\n",
      "Epoch 87/1000\n",
      "2341/2341 - 1s - loss: 0.6837 - accuracy: 0.5505 - val_loss: 0.6985 - val_accuracy: 0.5153\n",
      "Epoch 88/1000\n",
      "2341/2341 - 1s - loss: 0.6836 - accuracy: 0.5500 - val_loss: 0.6981 - val_accuracy: 0.5114\n",
      "Epoch 89/1000\n",
      "2341/2341 - 1s - loss: 0.6836 - accuracy: 0.5525 - val_loss: 0.6989 - val_accuracy: 0.5162\n",
      "Epoch 90/1000\n",
      "2341/2341 - 1s - loss: 0.6835 - accuracy: 0.5512 - val_loss: 0.6992 - val_accuracy: 0.5131\n",
      "Epoch 91/1000\n",
      "2341/2341 - 1s - loss: 0.6834 - accuracy: 0.5518 - val_loss: 0.6994 - val_accuracy: 0.5090\n",
      "Epoch 92/1000\n",
      "2341/2341 - 1s - loss: 0.6834 - accuracy: 0.5510 - val_loss: 0.6990 - val_accuracy: 0.5119\n",
      "Epoch 93/1000\n",
      "2341/2341 - 1s - loss: 0.6833 - accuracy: 0.5523 - val_loss: 0.6995 - val_accuracy: 0.5142\n",
      "Epoch 94/1000\n",
      "2341/2341 - 1s - loss: 0.6832 - accuracy: 0.5523 - val_loss: 0.7001 - val_accuracy: 0.5103\n",
      "Epoch 95/1000\n",
      "2341/2341 - 1s - loss: 0.6832 - accuracy: 0.5531 - val_loss: 0.6989 - val_accuracy: 0.5131\n",
      "Epoch 96/1000\n",
      "2341/2341 - 1s - loss: 0.6832 - accuracy: 0.5527 - val_loss: 0.6991 - val_accuracy: 0.5113\n",
      "Epoch 97/1000\n",
      "2341/2341 - 1s - loss: 0.6830 - accuracy: 0.5521 - val_loss: 0.6988 - val_accuracy: 0.5113\n",
      "Epoch 98/1000\n",
      "2341/2341 - 1s - loss: 0.6829 - accuracy: 0.5523 - val_loss: 0.6989 - val_accuracy: 0.5132\n",
      "Epoch 99/1000\n",
      "2341/2341 - 1s - loss: 0.6829 - accuracy: 0.5537 - val_loss: 0.6993 - val_accuracy: 0.5125\n",
      "Epoch 100/1000\n",
      "2341/2341 - 1s - loss: 0.6829 - accuracy: 0.5541 - val_loss: 0.6991 - val_accuracy: 0.5114\n",
      "Epoch 101/1000\n",
      "2341/2341 - 1s - loss: 0.6828 - accuracy: 0.5519 - val_loss: 0.6994 - val_accuracy: 0.5101\n",
      "Epoch 102/1000\n",
      "2341/2341 - 1s - loss: 0.6827 - accuracy: 0.5544 - val_loss: 0.6999 - val_accuracy: 0.5129\n",
      "Epoch 103/1000\n",
      "2341/2341 - 1s - loss: 0.6826 - accuracy: 0.5530 - val_loss: 0.6995 - val_accuracy: 0.5132\n",
      "Epoch 104/1000\n",
      "2341/2341 - 1s - loss: 0.6827 - accuracy: 0.5532 - val_loss: 0.7002 - val_accuracy: 0.5103\n",
      "Epoch 105/1000\n",
      "2341/2341 - 1s - loss: 0.6825 - accuracy: 0.5544 - val_loss: 0.7005 - val_accuracy: 0.5100\n",
      "Epoch 106/1000\n",
      "2341/2341 - 1s - loss: 0.6825 - accuracy: 0.5537 - val_loss: 0.7001 - val_accuracy: 0.5126\n",
      "Epoch 107/1000\n",
      "2341/2341 - 1s - loss: 0.6824 - accuracy: 0.5536 - val_loss: 0.7008 - val_accuracy: 0.5113\n",
      "Epoch 108/1000\n",
      "2341/2341 - 1s - loss: 0.6824 - accuracy: 0.5538 - val_loss: 0.7011 - val_accuracy: 0.5105\n",
      "Epoch 109/1000\n",
      "2341/2341 - 1s - loss: 0.6823 - accuracy: 0.5539 - val_loss: 0.7001 - val_accuracy: 0.5130\n",
      "Epoch 110/1000\n",
      "2341/2341 - 1s - loss: 0.6821 - accuracy: 0.5552 - val_loss: 0.7006 - val_accuracy: 0.5120\n",
      "Epoch 111/1000\n",
      "2341/2341 - 1s - loss: 0.6822 - accuracy: 0.5550 - val_loss: 0.7009 - val_accuracy: 0.5125\n",
      "Epoch 112/1000\n",
      "2341/2341 - 1s - loss: 0.6822 - accuracy: 0.5559 - val_loss: 0.7009 - val_accuracy: 0.5125\n",
      "Epoch 113/1000\n",
      "2341/2341 - 1s - loss: 0.6821 - accuracy: 0.5545 - val_loss: 0.7004 - val_accuracy: 0.5159\n",
      "Epoch 114/1000\n",
      "2341/2341 - 1s - loss: 0.6820 - accuracy: 0.5550 - val_loss: 0.7017 - val_accuracy: 0.5097\n",
      "Epoch 115/1000\n",
      "2341/2341 - 1s - loss: 0.6820 - accuracy: 0.5550 - val_loss: 0.7008 - val_accuracy: 0.5108\n",
      "Epoch 116/1000\n",
      "2341/2341 - 1s - loss: 0.6818 - accuracy: 0.5562 - val_loss: 0.7014 - val_accuracy: 0.5090\n",
      "Epoch 117/1000\n",
      "2341/2341 - 1s - loss: 0.6818 - accuracy: 0.5572 - val_loss: 0.7016 - val_accuracy: 0.5119\n",
      "Epoch 118/1000\n",
      "2341/2341 - 1s - loss: 0.6818 - accuracy: 0.5565 - val_loss: 0.7013 - val_accuracy: 0.5133\n",
      "Epoch 119/1000\n",
      "2341/2341 - 1s - loss: 0.6818 - accuracy: 0.5558 - val_loss: 0.7013 - val_accuracy: 0.5115\n",
      "Epoch 120/1000\n",
      "2341/2341 - 1s - loss: 0.6817 - accuracy: 0.5553 - val_loss: 0.7008 - val_accuracy: 0.5117\n",
      "Epoch 121/1000\n",
      "2341/2341 - 1s - loss: 0.6817 - accuracy: 0.5549 - val_loss: 0.7012 - val_accuracy: 0.5130\n",
      "Epoch 122/1000\n",
      "2341/2341 - 1s - loss: 0.6815 - accuracy: 0.5564 - val_loss: 0.7017 - val_accuracy: 0.5102\n",
      "Epoch 123/1000\n",
      "2341/2341 - 1s - loss: 0.6816 - accuracy: 0.5577 - val_loss: 0.7002 - val_accuracy: 0.5108\n",
      "Epoch 124/1000\n",
      "2341/2341 - 1s - loss: 0.6815 - accuracy: 0.5571 - val_loss: 0.7025 - val_accuracy: 0.5097\n",
      "Epoch 125/1000\n",
      "2341/2341 - 2s - loss: 0.6814 - accuracy: 0.5558 - val_loss: 0.7015 - val_accuracy: 0.5117\n",
      "Epoch 126/1000\n",
      "2341/2341 - 2s - loss: 0.6813 - accuracy: 0.5568 - val_loss: 0.7017 - val_accuracy: 0.5120\n",
      "Epoch 127/1000\n",
      "2341/2341 - 2s - loss: 0.6812 - accuracy: 0.5567 - val_loss: 0.7024 - val_accuracy: 0.5126\n",
      "Epoch 128/1000\n",
      "2341/2341 - 2s - loss: 0.6813 - accuracy: 0.5558 - val_loss: 0.7020 - val_accuracy: 0.5076\n",
      "Epoch 129/1000\n",
      "2341/2341 - 1s - loss: 0.6812 - accuracy: 0.5578 - val_loss: 0.7015 - val_accuracy: 0.5136\n",
      "Epoch 130/1000\n",
      "2341/2341 - 2s - loss: 0.6811 - accuracy: 0.5575 - val_loss: 0.7024 - val_accuracy: 0.5113\n",
      "Epoch 131/1000\n",
      "2341/2341 - 2s - loss: 0.6811 - accuracy: 0.5571 - val_loss: 0.7013 - val_accuracy: 0.5145\n",
      "Epoch 132/1000\n",
      "2341/2341 - 2s - loss: 0.6810 - accuracy: 0.5597 - val_loss: 0.7021 - val_accuracy: 0.5121\n",
      "Epoch 133/1000\n",
      "2341/2341 - 2s - loss: 0.6810 - accuracy: 0.5589 - val_loss: 0.7019 - val_accuracy: 0.5102\n",
      "Epoch 134/1000\n",
      "2341/2341 - 1s - loss: 0.6809 - accuracy: 0.5577 - val_loss: 0.7009 - val_accuracy: 0.5107\n",
      "Epoch 135/1000\n",
      "2341/2341 - 1s - loss: 0.6809 - accuracy: 0.5575 - val_loss: 0.7021 - val_accuracy: 0.5121\n",
      "Epoch 136/1000\n",
      "2341/2341 - 2s - loss: 0.6808 - accuracy: 0.5577 - val_loss: 0.7010 - val_accuracy: 0.5084\n",
      "Epoch 137/1000\n",
      "2341/2341 - 1s - loss: 0.6807 - accuracy: 0.5579 - val_loss: 0.7008 - val_accuracy: 0.5150\n",
      "Epoch 138/1000\n",
      "2341/2341 - 1s - loss: 0.6808 - accuracy: 0.5574 - val_loss: 0.7016 - val_accuracy: 0.5145\n",
      "Epoch 139/1000\n",
      "2341/2341 - 1s - loss: 0.6807 - accuracy: 0.5586 - val_loss: 0.7011 - val_accuracy: 0.5175\n",
      "Epoch 140/1000\n",
      "2341/2341 - 1s - loss: 0.6806 - accuracy: 0.5586 - val_loss: 0.7013 - val_accuracy: 0.5153\n",
      "Epoch 141/1000\n",
      "2341/2341 - 1s - loss: 0.6805 - accuracy: 0.5592 - val_loss: 0.7018 - val_accuracy: 0.5101\n",
      "Epoch 142/1000\n",
      "2341/2341 - 1s - loss: 0.6805 - accuracy: 0.5590 - val_loss: 0.7010 - val_accuracy: 0.5127\n",
      "Epoch 143/1000\n",
      "2341/2341 - 1s - loss: 0.6804 - accuracy: 0.5607 - val_loss: 0.7018 - val_accuracy: 0.5109\n",
      "Epoch 144/1000\n",
      "2341/2341 - 2s - loss: 0.6804 - accuracy: 0.5596 - val_loss: 0.7014 - val_accuracy: 0.5105\n",
      "Epoch 145/1000\n",
      "2341/2341 - 1s - loss: 0.6804 - accuracy: 0.5596 - val_loss: 0.7027 - val_accuracy: 0.5119\n",
      "Epoch 146/1000\n",
      "2341/2341 - 1s - loss: 0.6803 - accuracy: 0.5594 - val_loss: 0.7030 - val_accuracy: 0.5154\n",
      "Epoch 147/1000\n",
      "2341/2341 - 1s - loss: 0.6802 - accuracy: 0.5587 - val_loss: 0.7040 - val_accuracy: 0.5105\n",
      "Epoch 148/1000\n",
      "2341/2341 - 2s - loss: 0.6803 - accuracy: 0.5588 - val_loss: 0.7016 - val_accuracy: 0.5147\n",
      "Epoch 149/1000\n",
      "2341/2341 - 2s - loss: 0.6801 - accuracy: 0.5593 - val_loss: 0.7007 - val_accuracy: 0.5101\n",
      "Epoch 150/1000\n",
      "2341/2341 - 2s - loss: 0.6801 - accuracy: 0.5601 - val_loss: 0.7014 - val_accuracy: 0.5156\n",
      "Epoch 151/1000\n",
      "2341/2341 - 1s - loss: 0.6801 - accuracy: 0.5597 - val_loss: 0.7025 - val_accuracy: 0.5133\n",
      "Epoch 152/1000\n",
      "2341/2341 - 1s - loss: 0.6800 - accuracy: 0.5613 - val_loss: 0.7028 - val_accuracy: 0.5131\n",
      "Epoch 153/1000\n",
      "2341/2341 - 2s - loss: 0.6799 - accuracy: 0.5611 - val_loss: 0.7007 - val_accuracy: 0.5157\n",
      "Epoch 154/1000\n",
      "2341/2341 - 1s - loss: 0.6800 - accuracy: 0.5596 - val_loss: 0.7030 - val_accuracy: 0.5129\n",
      "Epoch 155/1000\n",
      "2341/2341 - 2s - loss: 0.6799 - accuracy: 0.5605 - val_loss: 0.7026 - val_accuracy: 0.5163\n",
      "Epoch 156/1000\n",
      "2341/2341 - 2s - loss: 0.6797 - accuracy: 0.5589 - val_loss: 0.7026 - val_accuracy: 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/1000\n",
      "2341/2341 - 2s - loss: 0.6798 - accuracy: 0.5604 - val_loss: 0.7038 - val_accuracy: 0.5095\n",
      "Epoch 158/1000\n",
      "2341/2341 - 2s - loss: 0.6797 - accuracy: 0.5603 - val_loss: 0.7034 - val_accuracy: 0.5133\n",
      "Epoch 159/1000\n",
      "2341/2341 - 1s - loss: 0.6797 - accuracy: 0.5603 - val_loss: 0.7019 - val_accuracy: 0.5125\n",
      "Epoch 160/1000\n",
      "2341/2341 - 1s - loss: 0.6796 - accuracy: 0.5605 - val_loss: 0.7022 - val_accuracy: 0.5133\n",
      "Epoch 161/1000\n",
      "2341/2341 - 2s - loss: 0.6796 - accuracy: 0.5607 - val_loss: 0.7029 - val_accuracy: 0.5141\n",
      "Epoch 162/1000\n",
      "2341/2341 - 1s - loss: 0.6796 - accuracy: 0.5613 - val_loss: 0.7033 - val_accuracy: 0.5129\n",
      "Epoch 163/1000\n",
      "2341/2341 - 2s - loss: 0.6795 - accuracy: 0.5622 - val_loss: 0.7036 - val_accuracy: 0.5162\n",
      "Epoch 164/1000\n",
      "2341/2341 - 1s - loss: 0.6794 - accuracy: 0.5609 - val_loss: 0.7018 - val_accuracy: 0.5143\n",
      "Epoch 165/1000\n",
      "2341/2341 - 2s - loss: 0.6793 - accuracy: 0.5597 - val_loss: 0.7026 - val_accuracy: 0.5150\n",
      "Epoch 166/1000\n",
      "2341/2341 - 1s - loss: 0.6794 - accuracy: 0.5604 - val_loss: 0.7028 - val_accuracy: 0.5106\n",
      "Epoch 167/1000\n",
      "2341/2341 - 1s - loss: 0.6793 - accuracy: 0.5617 - val_loss: 0.7023 - val_accuracy: 0.5155\n",
      "Epoch 168/1000\n",
      "2341/2341 - 2s - loss: 0.6792 - accuracy: 0.5617 - val_loss: 0.7021 - val_accuracy: 0.5119\n",
      "Epoch 169/1000\n",
      "2341/2341 - 1s - loss: 0.6792 - accuracy: 0.5626 - val_loss: 0.7038 - val_accuracy: 0.5167\n",
      "Epoch 170/1000\n",
      "2341/2341 - 2s - loss: 0.6791 - accuracy: 0.5605 - val_loss: 0.7024 - val_accuracy: 0.5144\n",
      "Epoch 171/1000\n",
      "2341/2341 - 1s - loss: 0.6791 - accuracy: 0.5610 - val_loss: 0.7026 - val_accuracy: 0.5138\n",
      "Epoch 172/1000\n",
      "2341/2341 - 2s - loss: 0.6791 - accuracy: 0.5620 - val_loss: 0.7029 - val_accuracy: 0.5117\n",
      "Epoch 173/1000\n",
      "2341/2341 - 2s - loss: 0.6790 - accuracy: 0.5620 - val_loss: 0.7026 - val_accuracy: 0.5168\n",
      "Epoch 174/1000\n",
      "2341/2341 - 2s - loss: 0.6790 - accuracy: 0.5616 - val_loss: 0.7027 - val_accuracy: 0.5154\n",
      "Epoch 175/1000\n",
      "2341/2341 - 1s - loss: 0.6790 - accuracy: 0.5620 - val_loss: 0.7039 - val_accuracy: 0.5178\n",
      "Epoch 176/1000\n",
      "2341/2341 - 2s - loss: 0.6789 - accuracy: 0.5601 - val_loss: 0.7041 - val_accuracy: 0.5160\n",
      "Epoch 177/1000\n",
      "2341/2341 - 2s - loss: 0.6789 - accuracy: 0.5631 - val_loss: 0.7028 - val_accuracy: 0.5202\n",
      "Epoch 178/1000\n",
      "2341/2341 - 2s - loss: 0.6790 - accuracy: 0.5623 - val_loss: 0.7021 - val_accuracy: 0.5142\n",
      "Epoch 179/1000\n",
      "2341/2341 - 2s - loss: 0.6787 - accuracy: 0.5633 - val_loss: 0.7041 - val_accuracy: 0.5148\n",
      "Epoch 180/1000\n",
      "2341/2341 - 2s - loss: 0.6788 - accuracy: 0.5622 - val_loss: 0.7042 - val_accuracy: 0.5137\n",
      "Epoch 181/1000\n",
      "2341/2341 - 2s - loss: 0.6787 - accuracy: 0.5632 - val_loss: 0.7026 - val_accuracy: 0.5169\n",
      "Epoch 182/1000\n",
      "2341/2341 - 2s - loss: 0.6787 - accuracy: 0.5622 - val_loss: 0.7034 - val_accuracy: 0.5153\n",
      "Epoch 183/1000\n",
      "2341/2341 - 2s - loss: 0.6787 - accuracy: 0.5627 - val_loss: 0.7032 - val_accuracy: 0.5125\n",
      "Epoch 184/1000\n",
      "2341/2341 - 2s - loss: 0.6786 - accuracy: 0.5629 - val_loss: 0.7024 - val_accuracy: 0.5155\n",
      "Epoch 185/1000\n",
      "2341/2341 - 1s - loss: 0.6784 - accuracy: 0.5630 - val_loss: 0.7035 - val_accuracy: 0.5147\n",
      "Epoch 186/1000\n",
      "2341/2341 - 2s - loss: 0.6785 - accuracy: 0.5626 - val_loss: 0.7023 - val_accuracy: 0.5147\n",
      "Epoch 187/1000\n",
      "2341/2341 - 1s - loss: 0.6784 - accuracy: 0.5622 - val_loss: 0.7043 - val_accuracy: 0.5150\n",
      "Epoch 188/1000\n",
      "2341/2341 - 1s - loss: 0.6783 - accuracy: 0.5640 - val_loss: 0.7037 - val_accuracy: 0.5187\n",
      "Epoch 189/1000\n",
      "2341/2341 - 1s - loss: 0.6782 - accuracy: 0.5619 - val_loss: 0.7028 - val_accuracy: 0.5143\n",
      "Epoch 190/1000\n",
      "2341/2341 - 2s - loss: 0.6783 - accuracy: 0.5625 - val_loss: 0.7036 - val_accuracy: 0.5160\n",
      "Epoch 191/1000\n",
      "2341/2341 - 2s - loss: 0.6784 - accuracy: 0.5630 - val_loss: 0.7033 - val_accuracy: 0.5153\n",
      "Epoch 192/1000\n",
      "2341/2341 - 2s - loss: 0.6782 - accuracy: 0.5635 - val_loss: 0.7038 - val_accuracy: 0.5121\n",
      "Epoch 193/1000\n",
      "2341/2341 - 2s - loss: 0.6782 - accuracy: 0.5624 - val_loss: 0.7064 - val_accuracy: 0.5149\n",
      "Epoch 194/1000\n",
      "2341/2341 - 2s - loss: 0.6780 - accuracy: 0.5634 - val_loss: 0.7034 - val_accuracy: 0.5177\n",
      "Epoch 195/1000\n",
      "2341/2341 - 2s - loss: 0.6780 - accuracy: 0.5640 - val_loss: 0.7040 - val_accuracy: 0.5155\n",
      "Epoch 196/1000\n",
      "2341/2341 - 1s - loss: 0.6779 - accuracy: 0.5635 - val_loss: 0.7041 - val_accuracy: 0.5148\n",
      "Epoch 197/1000\n",
      "2341/2341 - 1s - loss: 0.6780 - accuracy: 0.5633 - val_loss: 0.7035 - val_accuracy: 0.5123\n",
      "Epoch 198/1000\n",
      "2341/2341 - 1s - loss: 0.6780 - accuracy: 0.5633 - val_loss: 0.7044 - val_accuracy: 0.5131\n",
      "Epoch 199/1000\n",
      "2341/2341 - 1s - loss: 0.6779 - accuracy: 0.5636 - val_loss: 0.7052 - val_accuracy: 0.5135\n",
      "Epoch 200/1000\n",
      "2341/2341 - 1s - loss: 0.6778 - accuracy: 0.5643 - val_loss: 0.7052 - val_accuracy: 0.5120\n",
      "Epoch 201/1000\n",
      "2341/2341 - 1s - loss: 0.6778 - accuracy: 0.5639 - val_loss: 0.7046 - val_accuracy: 0.5111\n",
      "Epoch 202/1000\n",
      "2341/2341 - 1s - loss: 0.6779 - accuracy: 0.5640 - val_loss: 0.7042 - val_accuracy: 0.5175\n",
      "Epoch 203/1000\n",
      "2341/2341 - 2s - loss: 0.6778 - accuracy: 0.5632 - val_loss: 0.7047 - val_accuracy: 0.5113\n",
      "Epoch 204/1000\n",
      "2341/2341 - 2s - loss: 0.6777 - accuracy: 0.5644 - val_loss: 0.7046 - val_accuracy: 0.5144\n",
      "Epoch 205/1000\n",
      "2341/2341 - 2s - loss: 0.6777 - accuracy: 0.5653 - val_loss: 0.7044 - val_accuracy: 0.5106\n",
      "Epoch 206/1000\n",
      "2341/2341 - 1s - loss: 0.6776 - accuracy: 0.5644 - val_loss: 0.7049 - val_accuracy: 0.5137\n",
      "Epoch 207/1000\n",
      "2341/2341 - 1s - loss: 0.6777 - accuracy: 0.5636 - val_loss: 0.7054 - val_accuracy: 0.5147\n",
      "Epoch 208/1000\n",
      "2341/2341 - 1s - loss: 0.6776 - accuracy: 0.5647 - val_loss: 0.7047 - val_accuracy: 0.5168\n",
      "Epoch 209/1000\n",
      "2341/2341 - 2s - loss: 0.6775 - accuracy: 0.5640 - val_loss: 0.7056 - val_accuracy: 0.5151\n",
      "Epoch 210/1000\n",
      "2341/2341 - 2s - loss: 0.6774 - accuracy: 0.5646 - val_loss: 0.7066 - val_accuracy: 0.5162\n",
      "Epoch 211/1000\n",
      "2341/2341 - 2s - loss: 0.6775 - accuracy: 0.5649 - val_loss: 0.7031 - val_accuracy: 0.5160\n",
      "Epoch 212/1000\n",
      "2341/2341 - 2s - loss: 0.6774 - accuracy: 0.5644 - val_loss: 0.7051 - val_accuracy: 0.5125\n",
      "Epoch 213/1000\n",
      "2341/2341 - 1s - loss: 0.6773 - accuracy: 0.5637 - val_loss: 0.7042 - val_accuracy: 0.5167\n",
      "Epoch 214/1000\n",
      "2341/2341 - 1s - loss: 0.6773 - accuracy: 0.5651 - val_loss: 0.7047 - val_accuracy: 0.5142\n",
      "Epoch 215/1000\n",
      "2341/2341 - 2s - loss: 0.6771 - accuracy: 0.5661 - val_loss: 0.7055 - val_accuracy: 0.5123\n",
      "Epoch 216/1000\n",
      "2341/2341 - 1s - loss: 0.6773 - accuracy: 0.5650 - val_loss: 0.7053 - val_accuracy: 0.5136\n",
      "Epoch 217/1000\n",
      "2341/2341 - 1s - loss: 0.6773 - accuracy: 0.5647 - val_loss: 0.7036 - val_accuracy: 0.5153\n",
      "Epoch 218/1000\n",
      "2341/2341 - 1s - loss: 0.6771 - accuracy: 0.5652 - val_loss: 0.7051 - val_accuracy: 0.5163\n",
      "Epoch 219/1000\n",
      "2341/2341 - 1s - loss: 0.6770 - accuracy: 0.5636 - val_loss: 0.7041 - val_accuracy: 0.5131\n",
      "Epoch 220/1000\n",
      "2341/2341 - 1s - loss: 0.6771 - accuracy: 0.5660 - val_loss: 0.7048 - val_accuracy: 0.5142\n",
      "Epoch 221/1000\n",
      "2341/2341 - 1s - loss: 0.6770 - accuracy: 0.5655 - val_loss: 0.7048 - val_accuracy: 0.5117\n",
      "Epoch 222/1000\n",
      "2341/2341 - 1s - loss: 0.6770 - accuracy: 0.5650 - val_loss: 0.7037 - val_accuracy: 0.5124\n",
      "Epoch 223/1000\n",
      "2341/2341 - 1s - loss: 0.6769 - accuracy: 0.5647 - val_loss: 0.7051 - val_accuracy: 0.5148\n",
      "Epoch 224/1000\n",
      "2341/2341 - 1s - loss: 0.6769 - accuracy: 0.5650 - val_loss: 0.7056 - val_accuracy: 0.5163\n",
      "Epoch 225/1000\n",
      "2341/2341 - 1s - loss: 0.6769 - accuracy: 0.5645 - val_loss: 0.7047 - val_accuracy: 0.5143\n",
      "Epoch 226/1000\n",
      "2341/2341 - 1s - loss: 0.6769 - accuracy: 0.5651 - val_loss: 0.7043 - val_accuracy: 0.5168\n",
      "Epoch 227/1000\n",
      "2341/2341 - 2s - loss: 0.6769 - accuracy: 0.5645 - val_loss: 0.7042 - val_accuracy: 0.5141\n",
      "Epoch 228/1000\n",
      "2341/2341 - 2s - loss: 0.6768 - accuracy: 0.5656 - val_loss: 0.7052 - val_accuracy: 0.5125\n",
      "Epoch 229/1000\n",
      "2341/2341 - 2s - loss: 0.6767 - accuracy: 0.5651 - val_loss: 0.7053 - val_accuracy: 0.5153\n",
      "Epoch 230/1000\n",
      "2341/2341 - 1s - loss: 0.6768 - accuracy: 0.5649 - val_loss: 0.7052 - val_accuracy: 0.5107\n",
      "Epoch 231/1000\n",
      "2341/2341 - 1s - loss: 0.6767 - accuracy: 0.5654 - val_loss: 0.7062 - val_accuracy: 0.5149\n",
      "Epoch 232/1000\n",
      "2341/2341 - 1s - loss: 0.6767 - accuracy: 0.5662 - val_loss: 0.7068 - val_accuracy: 0.5120\n",
      "Epoch 233/1000\n",
      "2341/2341 - 2s - loss: 0.6766 - accuracy: 0.5657 - val_loss: 0.7056 - val_accuracy: 0.5168\n",
      "Epoch 234/1000\n",
      "2341/2341 - 1s - loss: 0.6766 - accuracy: 0.5655 - val_loss: 0.7052 - val_accuracy: 0.5143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/1000\n",
      "2341/2341 - 1s - loss: 0.6766 - accuracy: 0.5658 - val_loss: 0.7071 - val_accuracy: 0.5163\n",
      "Epoch 236/1000\n",
      "2341/2341 - 2s - loss: 0.6766 - accuracy: 0.5664 - val_loss: 0.7048 - val_accuracy: 0.5123\n",
      "Epoch 237/1000\n",
      "2341/2341 - 2s - loss: 0.6764 - accuracy: 0.5664 - val_loss: 0.7058 - val_accuracy: 0.5159\n",
      "Epoch 238/1000\n",
      "2341/2341 - 1s - loss: 0.6764 - accuracy: 0.5657 - val_loss: 0.7065 - val_accuracy: 0.5109\n",
      "Epoch 239/1000\n",
      "2341/2341 - 1s - loss: 0.6764 - accuracy: 0.5663 - val_loss: 0.7047 - val_accuracy: 0.5145\n",
      "Epoch 240/1000\n",
      "2341/2341 - 2s - loss: 0.6765 - accuracy: 0.5670 - val_loss: 0.7073 - val_accuracy: 0.5114\n",
      "Epoch 241/1000\n",
      "2341/2341 - 2s - loss: 0.6762 - accuracy: 0.5665 - val_loss: 0.7078 - val_accuracy: 0.5150\n",
      "Epoch 242/1000\n",
      "2341/2341 - 2s - loss: 0.6764 - accuracy: 0.5672 - val_loss: 0.7054 - val_accuracy: 0.5112\n",
      "Epoch 243/1000\n",
      "2341/2341 - 2s - loss: 0.6763 - accuracy: 0.5658 - val_loss: 0.7066 - val_accuracy: 0.5130\n",
      "Epoch 244/1000\n",
      "2341/2341 - 2s - loss: 0.6763 - accuracy: 0.5657 - val_loss: 0.7070 - val_accuracy: 0.5172\n",
      "Epoch 245/1000\n",
      "2341/2341 - 1s - loss: 0.6762 - accuracy: 0.5668 - val_loss: 0.7068 - val_accuracy: 0.5166\n",
      "Epoch 246/1000\n",
      "2341/2341 - 1s - loss: 0.6761 - accuracy: 0.5654 - val_loss: 0.7069 - val_accuracy: 0.5132\n",
      "Epoch 247/1000\n",
      "2341/2341 - 2s - loss: 0.6761 - accuracy: 0.5659 - val_loss: 0.7066 - val_accuracy: 0.5126\n",
      "Epoch 248/1000\n",
      "2341/2341 - 2s - loss: 0.6761 - accuracy: 0.5668 - val_loss: 0.7068 - val_accuracy: 0.5169\n",
      "Epoch 249/1000\n",
      "2341/2341 - 2s - loss: 0.6761 - accuracy: 0.5662 - val_loss: 0.7068 - val_accuracy: 0.5112\n",
      "Epoch 250/1000\n",
      "2341/2341 - 2s - loss: 0.6760 - accuracy: 0.5664 - val_loss: 0.7048 - val_accuracy: 0.5138\n",
      "Epoch 251/1000\n",
      "2341/2341 - 2s - loss: 0.6760 - accuracy: 0.5660 - val_loss: 0.7072 - val_accuracy: 0.5142\n",
      "Epoch 252/1000\n",
      "2341/2341 - 1s - loss: 0.6760 - accuracy: 0.5667 - val_loss: 0.7070 - val_accuracy: 0.5131\n",
      "Epoch 253/1000\n",
      "2341/2341 - 2s - loss: 0.6759 - accuracy: 0.5664 - val_loss: 0.7062 - val_accuracy: 0.5144\n",
      "Epoch 254/1000\n",
      "2341/2341 - 1s - loss: 0.6757 - accuracy: 0.5663 - val_loss: 0.7084 - val_accuracy: 0.5160\n",
      "Epoch 255/1000\n",
      "2341/2341 - 1s - loss: 0.6759 - accuracy: 0.5661 - val_loss: 0.7066 - val_accuracy: 0.5109\n",
      "Epoch 256/1000\n",
      "2341/2341 - 1s - loss: 0.6758 - accuracy: 0.5662 - val_loss: 0.7063 - val_accuracy: 0.5161\n",
      "Epoch 257/1000\n",
      "2341/2341 - 1s - loss: 0.6759 - accuracy: 0.5666 - val_loss: 0.7065 - val_accuracy: 0.5147\n",
      "Epoch 258/1000\n",
      "2341/2341 - 1s - loss: 0.6757 - accuracy: 0.5676 - val_loss: 0.7061 - val_accuracy: 0.5161\n",
      "Epoch 259/1000\n",
      "2341/2341 - 1s - loss: 0.6758 - accuracy: 0.5676 - val_loss: 0.7077 - val_accuracy: 0.5137\n",
      "Epoch 260/1000\n",
      "2341/2341 - 1s - loss: 0.6757 - accuracy: 0.5666 - val_loss: 0.7063 - val_accuracy: 0.5153\n",
      "Epoch 261/1000\n",
      "2341/2341 - 1s - loss: 0.6757 - accuracy: 0.5670 - val_loss: 0.7074 - val_accuracy: 0.5153\n",
      "Epoch 262/1000\n",
      "2341/2341 - 1s - loss: 0.6757 - accuracy: 0.5663 - val_loss: 0.7070 - val_accuracy: 0.5151\n",
      "Epoch 263/1000\n",
      "2341/2341 - 1s - loss: 0.6756 - accuracy: 0.5675 - val_loss: 0.7071 - val_accuracy: 0.5208\n",
      "Epoch 264/1000\n",
      "2341/2341 - 1s - loss: 0.6757 - accuracy: 0.5675 - val_loss: 0.7060 - val_accuracy: 0.5147\n",
      "Epoch 265/1000\n",
      "2341/2341 - 1s - loss: 0.6756 - accuracy: 0.5668 - val_loss: 0.7048 - val_accuracy: 0.5171\n",
      "Epoch 266/1000\n",
      "2341/2341 - 1s - loss: 0.6754 - accuracy: 0.5676 - val_loss: 0.7069 - val_accuracy: 0.5184\n",
      "Epoch 267/1000\n",
      "2341/2341 - 1s - loss: 0.6756 - accuracy: 0.5657 - val_loss: 0.7070 - val_accuracy: 0.5173\n",
      "Epoch 268/1000\n",
      "2341/2341 - 1s - loss: 0.6754 - accuracy: 0.5673 - val_loss: 0.7071 - val_accuracy: 0.5177\n",
      "Epoch 269/1000\n",
      "2341/2341 - 1s - loss: 0.6753 - accuracy: 0.5677 - val_loss: 0.7064 - val_accuracy: 0.5168\n",
      "Epoch 270/1000\n",
      "2341/2341 - 1s - loss: 0.6754 - accuracy: 0.5673 - val_loss: 0.7066 - val_accuracy: 0.5202\n",
      "Epoch 271/1000\n",
      "2341/2341 - 1s - loss: 0.6753 - accuracy: 0.5663 - val_loss: 0.7080 - val_accuracy: 0.5169\n",
      "Epoch 272/1000\n",
      "2341/2341 - 1s - loss: 0.6754 - accuracy: 0.5678 - val_loss: 0.7077 - val_accuracy: 0.5148\n",
      "Epoch 273/1000\n",
      "2341/2341 - 2s - loss: 0.6753 - accuracy: 0.5669 - val_loss: 0.7073 - val_accuracy: 0.5105\n",
      "Epoch 274/1000\n",
      "2341/2341 - 1s - loss: 0.6753 - accuracy: 0.5659 - val_loss: 0.7073 - val_accuracy: 0.5189\n",
      "Epoch 275/1000\n",
      "2341/2341 - 1s - loss: 0.6753 - accuracy: 0.5678 - val_loss: 0.7063 - val_accuracy: 0.5198\n",
      "Epoch 276/1000\n",
      "2341/2341 - 1s - loss: 0.6752 - accuracy: 0.5683 - val_loss: 0.7069 - val_accuracy: 0.5173\n",
      "Epoch 277/1000\n",
      "2341/2341 - 1s - loss: 0.6753 - accuracy: 0.5673 - val_loss: 0.7070 - val_accuracy: 0.5156\n",
      "Epoch 278/1000\n",
      "2341/2341 - 1s - loss: 0.6751 - accuracy: 0.5682 - val_loss: 0.7067 - val_accuracy: 0.5192\n",
      "Epoch 279/1000\n",
      "2341/2341 - 1s - loss: 0.6750 - accuracy: 0.5681 - val_loss: 0.7067 - val_accuracy: 0.5159\n",
      "Epoch 280/1000\n",
      "2341/2341 - 1s - loss: 0.6751 - accuracy: 0.5677 - val_loss: 0.7072 - val_accuracy: 0.5157\n",
      "Epoch 281/1000\n",
      "2341/2341 - 1s - loss: 0.6751 - accuracy: 0.5674 - val_loss: 0.7073 - val_accuracy: 0.5171\n",
      "Epoch 282/1000\n",
      "2341/2341 - 2s - loss: 0.6751 - accuracy: 0.5682 - val_loss: 0.7084 - val_accuracy: 0.5168\n",
      "Epoch 283/1000\n",
      "2341/2341 - 2s - loss: 0.6751 - accuracy: 0.5673 - val_loss: 0.7075 - val_accuracy: 0.5136\n",
      "Epoch 284/1000\n",
      "2341/2341 - 2s - loss: 0.6751 - accuracy: 0.5677 - val_loss: 0.7064 - val_accuracy: 0.5179\n",
      "Epoch 285/1000\n",
      "2341/2341 - 2s - loss: 0.6749 - accuracy: 0.5688 - val_loss: 0.7081 - val_accuracy: 0.5167\n",
      "Epoch 286/1000\n",
      "2341/2341 - 1s - loss: 0.6750 - accuracy: 0.5670 - val_loss: 0.7085 - val_accuracy: 0.5102\n",
      "Epoch 287/1000\n",
      "2341/2341 - 1s - loss: 0.6749 - accuracy: 0.5685 - val_loss: 0.7072 - val_accuracy: 0.5174\n",
      "Epoch 288/1000\n",
      "2341/2341 - 2s - loss: 0.6749 - accuracy: 0.5678 - val_loss: 0.7085 - val_accuracy: 0.5113\n",
      "Epoch 289/1000\n",
      "2341/2341 - 1s - loss: 0.6748 - accuracy: 0.5685 - val_loss: 0.7081 - val_accuracy: 0.5166\n",
      "Epoch 290/1000\n",
      "2341/2341 - 1s - loss: 0.6749 - accuracy: 0.5692 - val_loss: 0.7068 - val_accuracy: 0.5187\n",
      "Epoch 291/1000\n",
      "2341/2341 - 1s - loss: 0.6748 - accuracy: 0.5701 - val_loss: 0.7088 - val_accuracy: 0.5159\n",
      "Epoch 292/1000\n",
      "2341/2341 - 2s - loss: 0.6748 - accuracy: 0.5694 - val_loss: 0.7066 - val_accuracy: 0.5148\n",
      "Epoch 293/1000\n",
      "2341/2341 - 2s - loss: 0.6747 - accuracy: 0.5692 - val_loss: 0.7085 - val_accuracy: 0.5148\n",
      "Epoch 294/1000\n",
      "2341/2341 - 1s - loss: 0.6748 - accuracy: 0.5689 - val_loss: 0.7088 - val_accuracy: 0.5184\n",
      "Epoch 295/1000\n",
      "2341/2341 - 1s - loss: 0.6747 - accuracy: 0.5692 - val_loss: 0.7085 - val_accuracy: 0.5118\n",
      "Epoch 296/1000\n",
      "2341/2341 - 1s - loss: 0.6746 - accuracy: 0.5680 - val_loss: 0.7086 - val_accuracy: 0.5150\n",
      "Epoch 297/1000\n",
      "2341/2341 - 2s - loss: 0.6746 - accuracy: 0.5690 - val_loss: 0.7072 - val_accuracy: 0.5169\n",
      "Epoch 298/1000\n",
      "2341/2341 - 2s - loss: 0.6747 - accuracy: 0.5684 - val_loss: 0.7104 - val_accuracy: 0.5168\n",
      "Epoch 299/1000\n",
      "2341/2341 - 2s - loss: 0.6746 - accuracy: 0.5667 - val_loss: 0.7069 - val_accuracy: 0.5160\n",
      "Epoch 300/1000\n",
      "2341/2341 - 2s - loss: 0.6745 - accuracy: 0.5688 - val_loss: 0.7080 - val_accuracy: 0.5175\n",
      "Epoch 301/1000\n",
      "2341/2341 - 2s - loss: 0.6746 - accuracy: 0.5692 - val_loss: 0.7076 - val_accuracy: 0.5159\n",
      "Epoch 302/1000\n",
      "2341/2341 - 2s - loss: 0.6745 - accuracy: 0.5694 - val_loss: 0.7081 - val_accuracy: 0.5175\n",
      "Epoch 303/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f98ef62231a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(X_train, y_train, epochs=1000, batch_size = 32, verbose = 2, \n\u001b[0m\u001b[1;32m      2\u001b[0m           validation_data = (X_val, y_val))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size = 32, verbose = 2, \n",
    "          validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_val)\n",
    "y_pred_cat = [np.argmax(t) for t in y_pred]\n",
    "y_val_cat = [np.argmax(t) for t in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf_mat = confusion_matrix(y_val_cat, y_pred_cat, normalize = 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    \"\"\"\n",
    "    given a sklearn confusion matrix (cm), make a nice plot\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    cm:           confusion matrix from sklearn.metrics.confusion_matrix\n",
    "\n",
    "    target_names: given classification classes such as [0, 1, 2]\n",
    "                  the class names, for example: ['high', 'medium', 'low']\n",
    "\n",
    "    title:        the text to display at the top of the matrix\n",
    "\n",
    "    cmap:         the gradient of the values displayed from matplotlib.pyplot.cm\n",
    "                  see http://matplotlib.org/examples/color/colormaps_reference.html\n",
    "                  plt.get_cmap('jet') or plt.cm.Blues\n",
    "\n",
    "    normalize:    If False, plot the raw numbers\n",
    "                  If True, plot the proportions\n",
    "\n",
    "    Usage\n",
    "    -----\n",
    "    plot_confusion_matrix(cm           = cm,                  # confusion matrix created by\n",
    "                                                              # sklearn.metrics.confusion_matrix\n",
    "                          normalize    = True,                # show proportions\n",
    "                          target_names = y_labels_vals,       # list of names of the classes\n",
    "                          title        = best_estimator_name) # title of graph\n",
    "\n",
    "    Citiation\n",
    "    ---------\n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(conf_mat, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit08592e403cee4537bb5e90e452eed589"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
